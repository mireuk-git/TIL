![](tilThumb.webp)
---
# 오늘의 코드카타
> SQL 코드카타
https://school.programmers.co.kr/learn/courses/30/lessons/151141
```
SELECT H.HISTORY_ID,
CASE 
    WHEN DATEDIFF(H.END_DATE, H.START_DATE)+1 >= 7 THEN CONVERT(C.DAILY_FEE * (DATEDIFF(H.END_DATE, H.START_DATE)+1) * (1-D.DISCOUNT_RATE/100),SIGNED)
    ELSE (C.DAILY_FEE * (DATEDIFF(H.END_DATE, H.START_DATE)+1))
    END AS FEE
FROM CAR_RENTAL_COMPANY_CAR C JOIN CAR_RENTAL_COMPANY_RENTAL_HISTORY H
ON C.CAR_ID = H.CAR_ID
JOIN CAR_RENTAL_COMPANY_DISCOUNT_PLAN D
ON C.CAR_TYPE = D.CAR_TYPE
WHERE C.CAR_TYPE = '트럭'
    AND(
        (DATEDIFF(H.END_DATE, H.START_DATE)+1 BETWEEN 7 AND 29 AND D.DURATION_TYPE='7일 이상')
        OR 
        (DATEDIFF(H.END_DATE, H.START_DATE)+1 BETWEEN 30 AND 89 AND D.DURATION_TYPE='30일 이상')
        OR 
        (DATEDIFF(H.END_DATE, H.START_DATE)+1 >= 90 AND D.DURATION_TYPE='90일 이상')
        OR DATEDIFF(H.END_DATE, H.START_DATE)<7
    )
GROUP BY H.HISTORY_ID
ORDER BY FEE DESC, H.HISTORY_ID DESC 
```
WHERE절에서는 CASE절 보다는 AND와 OR를 더 많이 쓰는거 같다. 
날짜형의 차이를 구하는 메소드 DATEDIFF(끝날짜, 시작날짜)
7일 이하에 할인율이 적용안되는 걸 구현하느라 좀 힘들었다, 결국 CASE절로 출력값을 두개로 나눠서 해결했다. 

> 알고리즘 코드카타
https://school.programmers.co.kr/learn/courses/30/lessons/12939
```
def solution(s):
    s=list(map(int,s.split()))
    answer = f'{min(s)} {max(s)}'
    return answer
```

---
알고리즘 활용은 일단 뒷전으로... 이번시즌거 빠르게 끝내고 보는걸 목표로 해본다

# LLM
Large Language Model, **대형** 언어 모델
수십억개의 파라미터를 기반으로 대규모 텍스트 데이터를 학습해 자연어를 처리하고(NLP) 생성하는 AI모델

#### LLM 동작원리
학습 - 대규모 텍스트 데이터셋을 이용해 단어, 문장, 문맥의 패턴 인식, 새 데이터 생성 시 학습한 패턴 적용
토큰의 특성 학습?
추론 - 학습 완료된 LLM은 입력을 받을 때 이전의 **맥락을 기억**하고 활용하면서 그에 맞는 **추론**을 통해 답변 생성
미세조정 - 특정 도메인이나 용도에 맞춰 추가학습(미세조정) 가능, 답변의 정확성이 높아짐

#### 랜덤성
확률에 기반해 문장 생성, 새로운 문장을 만들어내는 능력의 핵심
토큰의 확률 분포 계산
"온도" - 낮으면 더 적은 랜덤성, 높으면 더 많은 랜덤성 ~~엔트로피?~~

#### 조건성
이전 입력 내용에 따라(컨텍스트, 맥락) 조건부 확률을 기반으로 결과 생성
프롬프트: 입력된 문장이나 질문이 뭔지에 따라 결과 변동 (묻는말에 대답함)
맥락기억: 이전문장이나 대화 흐름에 맞춰 답변 생성

Vector DB - 텍스트를 벡터 형태로 변환해 유사한 의미를 가진 텍스트를 효율적으로 검색

## RAG
Retrieveal-Augmented Generation, 검색 기반 생성 기법
> LLM 한계①
학습이 종료된 기존의 LLM 모델은 최신 정보나 특정 도메인 지식에 대해 한계를 가질 수 있다

→ 외부 데이터베이스나 문서에서 관련 정보 검색, 답변 생성

1. 사용자에게서 입력이 들어옴, 질문에 맞는 답변 생성 전 검색 시작
2. 벡터 DB, 기타 정보 저장소에서 질문과 관련된 문서 검색, 벡터화된 텍스트와 의미적으로 유사한 문서 검색
(DB에 데이터가 담겨있어야겠네)
3. 검색된 문서를 바탕으로 LLM이 최종답변 작성(자연어처리)

기존 LLM 모델과 달리 최신 정보의 활용이 가능
특정 도메인에 특화된 정보 제공 가능, 일반적인 LLM보다 더 정확한 정보 제공 가능
필요한 정보만 검색, LLM의 모든 지식을 외부에 의존하지 않아도 됨, 효율적, 속도도 유의미하게 빠름

## 벡터 DB
RAG가 사용하는 데이터베이스
벡터를 저장하고 빠르게 찾을 수 있음
embedding - 텍스트/이미지를 벡터로 변환, 비슷한 단어는 비슷한 벡터값을 가진다, RAG를 사용할때 벡터DB는 유사한 벡터를 가진 문서를 검색한다

1. 문서/텍스트를 의미적 정보를 담은 벡터로 임베딩(데이터 저장 단계)
2. 임베딩한 벡터를 Vector DB에 저장, 유사한 의미의 텍스트는 유사한 벡터값을 지님, 따라서 검색 효율이 뛰어남
3. 사용자가 검색어를 입력하면 해당 검색어를 임베딩해 유사한 벡터를 가진 문서를 검색


단순 키워드 매칭이 아니라 텍스트의 의미에 기반한 검색, 유사한 의미를 가진 텍스트도 검색 가능
이미지도 벡터화해서 응용가능
대량의 벡터 데이터를 매우 빠르게 처리 가능, 대규모 텍스트 데이터에 대해 효율적으로 검색 가능


## LangChain
LLM과 외부 리소스를 결합해 강력한 언어 기반 애플리케이션을 만들 수 있도록 돕는 프레임워크
데이터소스, API, 데이터베이스 등을 쉽게 통합 가능

LLM과 외부 데이터소스 결합, LLM이 외부 데이터를 처리하게 함
여러 LLM작업을 순차적으로 실행할 수 있는 워크플로우 제공
여러번의 대화 흐름 제어 가능, 대화형 AI개발에 큰 역할

Prompt체인: 여러 프롬프트를 연속적으로 연결해 복잡한 작업 수행
메모리 기능: 대화의 맥락을 유지
외부 리소스 통합: API, 데이터베이스, 웹 검색 등 다양한 외부 리소스 결합, LLM의 한계 보완