![](tilThumb.webp)
---
# 오늘의 코드카타
> SQL 코드카타
https://school.programmers.co.kr/learn/courses/30/lessons/133502
```
SELECT A.AUTHOR_ID, A.AUTHOR_NAME, B.CATEGORY, SUM(B.PRICE*S.SALES) AS TOTAL_SALES
FROM (BOOK B JOIN AUTHOR A ON B.AUTHOR_ID=A.AUTHOR_ID) 
JOIN BOOK_SALES S ON B.BOOK_ID = S.BOOK_ID
WHERE DATE_FORMAT(SALES_DATE, '%Y-%m') = '2022-01'
GROUP BY A.AUTHOR_NAME, B.CATEGORY
ORDER BY A.AUTHOR_ID ASC, B.CATEGORY DESC
```

>알고리즘 코드카타
https://school.programmers.co.kr/learn/courses/30/lessons/133502#qna
```
def solution(ingredient):
    answer = 0
    order=[1,2,3,1]
    index_left=0
    while 1 in ingredient[index_left:len(ingredient)-3]:
        index_left=ingredient.index(1,index_left)
        burger_flag=True
        for i in range(1,4):
            if ingredient[index_left+i] != order[i]:
                burger_flag=False
                break
        if burger_flag:
            for i in range(4):
                del ingredient[index_left]
            index_left=0
            answer+=1
        index_left+=1
    return answer
```
처음 생각한 코드, 구현할건 다 구현했으나 효율적이지 못해 정답처리받지 못함
시작점을 찾고 그 뒤에 햄버거가 완성되는지 확인, 성공했다면 해당 요소를 제거하고 개수에 +1
제거 후 처음부터 살펴보기에 효율이 안나오는 걸까?
```
def solution(ingredient):
    answer = 0
    st = [] 
    for i in range(len(ingredient)):
        st.append(ingredient[i])
        if(len(st)>=4 and ingredient[i] == 1):  
            n = len(st)
            if st[-2] == 3 and st[-3] == 2 and st[-4]==1: 
                for i in range(4):
                    st.pop()
                answer+=1
    return answer
```
이 코드의 경우엔 임시 리스트에 요소를 하나씩 옮기면서 끝점 후보를 기준으로 살펴보고 햄버거가 만들어지면 요소에서 빼면서 개수에 +1한다. 
내 코드와 달리 처음으로 돌아가 다시 살펴볼 필요가 없기에 더 효율적으로 동작한다. 

---

# 생성형 모델
## 오토인코더
생성형 모델에 반드시 들어감
입력 데이터를 압축하고 다시 복원하는 식으로 데이터를 표현
인코더+디코더
![](https://velog.velcdn.com/images/yw_j/post/8491fdea-0147-435b-903e-993326235212/image.png)
> - 인코더 - 입력을 저차원으로 압축, 중요한 특징을 추출
- 디코더 - 저차원표현을 다시 원래대로, 최대한 원본과 가깝게 복원
- 잠재공간 - 인코더로 생성된 저차원 표현 공간, 추출된 중요한 특징을 포함, 디코더가 원본으로 복원할 대상

차원축소, 잡음제거, 생성모델 등에 사용

오토인코더 종류
>오토인코더 
- 딥 오토인코더 - 깊이가 더 큼(딥러닝에서의 오토인코더), 복잡한 데이터 표현 학습에 유리 
- 변분 오토인코더 - 확률적 잠재공간 사용, 데이터 분포 학습(잠재분포 학습), 새로운 데이터 생성
- 희소 오토인코더 - 잠재 공간의 표현을 희소하게 유지(출력값중 많은 요소가 0), 중요특징만 학습
- 잡음 제거 오토인코더 - 입력 데이터에 잡음 추가하고 제거하는 학습, 데이터 복원 능력 향상, 결측치 처리에 사용할 수 있을까? 

## 생성형 모델
#### GAN
신경망 두개(생성자, 판별자)가 서로 경쟁하며 동시에 학습
![](https://velog.velcdn.com/images/yw_j/post/1860f2c1-51df-41d2-a01a-54ebc175baff/image.png)
- 생성자: 가짜 데이터 생성
랜덤 input, 가짜 데이터 생성, 최대한 실제 이미지와 유사하게
- 판별자: 진짜인지 가짜인지 판별
받은 이미지를 최대한 정확하게 판별

unconditional GAN: 아무런 조건없는 랜덤한 input에서 데이터 생성
conditional GAN: 데이터 생성에 조건 추가, 생성자와 판별자가 조건을 만족하여 데이터를 생성하고 평가

이미지 생성, 데이터증강, 스타일 변화 등 다양한 분야에서 뛰어남
고품질 데이터 생성, 다양한 작업에 활용가능
훈련이 불안정, 둘이 동시에 적절한 방향으로 학습이 이루어지게 컨트롤해야함
모드붕괴 - 생성자가 다양한 데이터를 만들어내지 못하고 비슷한 데이터만 만들어내는 현상

#### VAE
오토인코더 동작방식과 유사
잠재공간을 통계확률로 생성, 확률분포를 모델링
데이터의 일반적인 지식 습득
잠재변수 - 평균과 분산으로 표현되는 확률분포

> 입력변수 - 잠재변수에 평균과 분산으로 매핑
잠재변수 - 평균과 분산으로 정규분포에서 샘플링
Reparameterization Trick(재매개변수화 트릭) - 샘플링 과정을 표준 정규분포에서 샘플링, 변화
디코딩 - 샘플링된 잠재변수를 사용, 복원된 데이터 출력

솔직히 이해 못했다. 

손실함수
- contruction loss: 원래 데이터와 복원된 데이터간의 차이 최소화
- 인코더가 학습한 잠재분포와 정규분포간의 차이 최소화

새로운 데이터 생성가능, 다만 복잡해서 이해하기 쉽지 않음
학습 불안정

## 전이학습
transfer learning
이미 학습된 모델의 지식을 새로운 문제에 적용
데이터가 부족한 상황에서 유용
모델 학습 시간 단축, 성능 향상, 적은 데이터로도 학습 진행 가능
전이학습은 기존의 데이터에서 모델의 일부 레이어를 미세하게 조정하거나 추가하고 세부적인 학습을 더 진행함

특징추출기(Feature Extractor)
모델의 초기 층 고정(객체의 외곽선/색상 검출은 이미 쓸만함)
마지막 층만 재학습

미세조정(fine tuning)
모델의 전체를 새로운 데이터에 맞춰 재학습

구축과정
> 
사전학습된 모델 로드
사전 학습된 모델의 마지막 층을 수정
수정된 모델을 학습(특징추출기/미세조정)

---
상담내용
수식이 어떤 모델인지?
익숙해질때까지 이 수식은 이 모델이다
정의 활용방법 수식 위주로
하...함 주석 매줄에 박아?

보강용 서적
혼자 공부하는 머신러닝

트러블슈팅 코드 공부
